{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('vader_lexicon')\n",
    "import plotly.express as px \n",
    "import plotly.graph_objs as pgo\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75064e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv(\"df_clean.csv\",encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95691d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02659d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict sentiments using SentimentIntensityAnalyzer\n",
    "df['Sentiment'] = [sentiment.polarity_scores(text)[\"compound\"] for text in df[\"Text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c07b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tags for the sentiment values\n",
    "df['sentiment_tag'] = ['Positive' if label >= 0.05 else 'Negative' if label <= -0.05 else 'Neutral' for label in df['sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score from the sentiment values\n",
    "df['sentiment_score'] = [int(((label + 1) * 5 / 2) + 1) for label in df['sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('df_sentimentresults.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True) \n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77fa500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "true_labels = df['Score']\n",
    "predicted_labels = df['sentiment_score']\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c6422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "true_labels = df['Score']\n",
    "predicted_labels = df['sentiment_score']\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.sentiment_tag.value_counts().to_frame()\n",
    "# Convert the index to a column\n",
    "df_1 = df_1.reset_index()\n",
    "\n",
    "# Rename the columns if desired\n",
    "df_1.rename(columns={'index': 'sentiment_label','sentiment_tag':'values'}, inplace=True)\n",
    "# Pie chart\n",
    "labels = df_1['sentiment_label']\n",
    "sizes = df_1['values']\n",
    "\n",
    "fig1 = px.pie(df_1, values=sizes, names=labels, hole=.3,title='Sentiment tags distribution')\n",
    "fig1.write_html(\"Sentiment tags distribution.html\")\n",
    "\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10108bbd",
   "metadata": {},
   "source": [
    "### \"Users who frequently provides reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42439c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('df_clean.csv')\n",
    "user_id_counts = df['UserId'].value_counts()\n",
    "labels = user_id_counts[user_id_counts > 100].index\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e902ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_filtered = df.loc[df['UserId'].isin(labels)]\n",
    "df_filtered=df_filtered.groupby([\"UserId\"]).agg(mean_score=('Score',np.mean)).sort_values(by=\"mean_score\",ascending=False).reset_index()\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e297807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=px.bar(df_filtered,x='UserId',y='mean_score',title=\"Users who frequently provides reviews\")\n",
    "fig2.write_html(\"Users who frequently provides reviews.html\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d458dd",
   "metadata": {},
   "source": [
    "### \"Products average score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating average score for each product id\n",
    "import numpy as np\n",
    "df_temp=df.groupby([\"ProductId\"]).agg(mean_score=('Score',np.mean)).sort_values(by=\"mean_score\",ascending=False).reset_index()\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ae97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating tag creation\n",
    "def condition(x):\n",
    "    if x==5:\n",
    "        return \"top rating\"\n",
    "    elif x>=4:\n",
    "        return \"4+\"\n",
    "    elif x>=3:\n",
    "        return \"3+\"\n",
    "    elif x>=2:\n",
    "        return \"2+\"\n",
    "    elif x>=1:\n",
    "        return \"least rating\"\n",
    "    \n",
    "# Applying the conditions\n",
    "df_temp['rating'] = df_temp['mean_score'].apply(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b607e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#product id count with rating tags\n",
    "values=df_temp.rating.value_counts().to_frame()\n",
    "# Convert the index to a column\n",
    "values = values.reset_index()\n",
    "\n",
    "# Rename the columns if desired\n",
    "values.rename(columns={'index': 'rating_category'}, inplace=True)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7375bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Pie chart\n",
    "labels = values['rating_category']\n",
    "sizes = values['rating']\n",
    "fig3 = px.pie(df_1, values=sizes, names=labels, hole=.3,title='Products average score distribution')\n",
    "fig3.write_html(\"Products average score distribution.html\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dee615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
